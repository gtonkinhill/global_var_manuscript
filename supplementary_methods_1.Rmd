---
title: "Suplementary methods"
author: "Gerry Tonkin-Hill"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 12
    fig_height: 8
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8,
                      echo=TRUE, warning=FALSE, message=FALSE,
                      tidy=TRUE)
```


##Load libraries

```{r}
library(data.table)
library(dplyr)
library(ggfortify)
library(ggplot2)
library(Rtsne)
library(stringr)
library(starmie)
library(ggtree)
library(ape)
library(pheatmap)
library(proxy)
library(knitr)
library(glmnet)

cols <- c("#a6cee3","#1f78b4","#b2df8a","#33a02c","#fb9a99","#e31a1c","#fdbf6f","#ff7f00","#cab2d6","#6a3d9a","#ffff99","#b15928","#8dd3c7","#ffffb3","#bebada","#fb8072","#80b1d3","#fdb462","#b3de69","#fccde5","#d9d9d9","#bc80bd","#ccebc5","#ffed6f")
```



##Otu Analysis
First we need to relabel the reads of Tessema et al to include isolate information for clustering.
```{python, eval = FALSE}
from mungo.fasta import FastaReader

read_to_isolate={}
with open("./data/read_info.csv", 'rU') as infile:
  infile.next()
  for line in infile:
    line=line.strip().split(",")
    read_to_isolate[line[0]]=line[1]

with open("./processed_data/tessema2015_renamed.fas", 'w') as outfile:
  for h,s in FastaReader("./data/tessema2015.fas"):
    outfile.write(">"+read_to_isolate[h]+"."+h+"\n"+s+"\n")
```

We start by clustering the raw 454 reads along with the reads from Tessema et al using a python script that makes use of the Usearch software suite.
```{bash, eval = FALSE}
cat ./data/combined_all_454_noPOR.fasta ./processed_data/tessema2015_renamed.fas > ./processed_data/combined_454_tessema.fas

python ~/clusterDBLa/clusterDBLa.py \
  -o ./processed_data/ \
  -r ./processed_data/combined_454_tessema.fas \
  --cpu 20
```

###Binary Analysis

Now we can investigate the isolates based on shared DBLa sequence types.

```{r}
isolateInformation <- fread("./data/isolate_information.csv"
                            , header=TRUE
                            , data.table = FALSE)
#Add in country information
isolateInformation$Country <- unlist(lapply(isolateInformation$Location
                                            , function(x) {
                                              str_split(x,  "_", n=2)[[1]][[1]]}))

#Remove duplicate entries of isolates that have been sequenced more than once
isolateInformation <- isolateInformation[!duplicated(isolateInformation$Isolate),]

otuTable <- fread("./processed_data/combined_454_tessema_renamed_otuTable_binary.txt"
                  , data.table = FALSE
                  , header=TRUE)

otuMatrix <- as.matrix(otuTable[,2:ncol(otuTable)])
rownames(otuMatrix) <- otuTable$`#OTU ID`
```

We found a total of `r sum(otuMatrix)` reads in the combined dataset, which clustered into a total of `r nrow(otuMatrix)`. Of these `r sum(rowSums(otuMatrix)==1)` were only seen in one isolate.


We next perform some filtering. We exclude the lab isolates and only investigate isolates that were found to have more than 20 DBLa types. This was found to be a sensible thresholf on having adequetly sequences an isolates VAR repetoir. Furthermore as we are interested in the realtionship between isolates we exclude the singletons from the binary analysis.
```{r}
#Filter otus that only appear in one isolate and isolates with less than 20 types
MIN_ISOLATE_PER_OTU = 2
MIN_OTUS_PER_ISOLATE = 20
MAX_OTUS_PER_ISOLATE = Inf
otuMatrix <- otuMatrix[, colSums(otuMatrix) >= MIN_OTUS_PER_ISOLATE]
otuMatrix <- otuMatrix[, colSums(otuMatrix) <= MAX_OTUS_PER_ISOLATE]

#Remove lab isolates
otuMatrixNoLab <- otuMatrix[,!(colnames(otuMatrix) %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2"))]
otuMatrixNoLab <- otuMatrixNoLab[rowSums(otuMatrixNoLab) >= MIN_ISOLATE_PER_OTU, ]
```

Identify which OTU centroids match with the 3D7 refernce for later infestigation.
```{bash, eval=FALSE}
usearch -usearch_global ./data/3D7.fasta -db ./data/combined_all_454_noPOR.fasta -id 0.96 -strand both -blast6out ./processed_data/3D7_vs_all_blast6out.txt -maxaccepts 0 -maxrejects 0
```

```{r}
otu_match_3D7 <- unique(fread("./processed_data/3D7_vs_all_blast6out.txt", data.table = FALSE)[,2])
sum(colnames(otuMatrixNoLab_t) %in% otu_match_3D7)
```

We can now look at the number of reads per isolate for the different countries.
```{r}
otu_sums <- data.frame(Isolate=colnames(otuMatrixNoLab), num_otus=colSums(otuMatrixNoLab)
                       , stringsAsFactors = FALSE)
  
otu_sums <- merge(otu_sums, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

median_summary <- otu_sums %>% group_by(Country) %>% 
  summarise(n=n(),
            median=median(num_otus),
            max=max(num_otus))
  
#boxplot plot 
gg <- ggplot(otu_sums, aes(factor(Country), num_otus, fill=Country)) + geom_boxplot()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

We can also compare the number of type A and type B/C VAR genes.
```{bash, eval=FALSE}
python ./scripts/allocate_reads_to_domains.py --fasta ./processed_data/combined_454_tessema_renamed_centroids.fasta --hmm ./data/all_protein_exon1_domain_HMMs.hmm --out_dir ./processed_data/
```

```{r}
type_freq_df <- data.frame(otu=rownames(otuMatrixNoLab)
                           , num_isolates=rowSums(otuMatrixNoLab)
                           , stringsAsFactors = FALSE)
type_allocations <- fread("./processed_data/combined_454_tessema_renamed_centroids_domainAllocations.csv", sep=",", header=TRUE, data.table = FALSE)
type_allocations$read <- gsub(";sample.*", "", type_allocations$read)
type_freq_df <- merge(type_freq_df, type_allocations
                      ,by.x = "otu", by.y="read", all.x=TRUE)
type_freq_df$type[grepl("DBLa1", type_freq_df$domain)] <- "A"
type_freq_df$type[!grepl("DBLa1", type_freq_df$domain)] <- "B/C"

#Remove rares
type_freq_df <- type_freq_df[type_freq_df$num_isolates>1,]

#boxplot
gg <- ggplot(type_freq_df, aes(factor(type), num_isolates, fill=type)) + geom_boxplot()
gg <- gg + theme_bw()
gg <- gg + scale_y_log10()
gg
```

###PCA
```{r}
otuMatrixNoLab_t <- t(otuMatrixNoLab)

pca <- prcomp(otuMatrixNoLab_t)

pca <- data.frame(Isolate = rownames(otuMatrixNoLab_t)
                     , pca$x[, 1:6]
                     , stringsAsFactors = FALSE)

pca <- merge(pca, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

#PCA plot
gg <- ggplot(pca, aes(PC1, PC2, colour=Country)) + geom_point() 
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw()
gg
```

Also worth looking at the 3rd and 4th principal components that appear to split mainly on the different African countries.
```{r}
#PCA plot
gg <- ggplot(pca, aes(PC3, PC4, colour=Country)) + geom_point() 
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw()
gg
```


###TSNE
```{r}
pca_tsne <- prcomp(otuMatrixNoLab_t, scale. = TRUE)

tsne <- Rtsne(pca_tsne$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne_df <- data.frame(Isolate=rownames(otuMatrixNoLab_t)
                      , x=tsne$Y[,1], y=tsne$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)
                      , stringsAsFactors = FALSE)
tsne_df <- merge(tsne_df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw()
gg
```

Check the impact of ignoring types found in 3D7
```{r}
pca_tsne2 <- prcomp(otuMatrixNoLab_t[,!(colnames(otuMatrixNoLab_t) %in% otu_match_3D7)], scale. = TRUE)

tsne2 <- Rtsne(pca_tsne2$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne_df2 <- data.frame(Isolate=rownames(otuMatrixNoLab_t)
                      , x=tsne2$Y[,1], y=tsne2$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)
                      , stringsAsFactors = FALSE)
tsne_df2 <- merge(tsne_df2, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne_df2, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw()
gg
```

Investigate the impact of possible cofounders

We don't have very high resolution data on age so perhaps the best we can do is split into exclusively young and 'other' datasets.

```{r}
tsne_df$Age.aggregated <- tsne_df$Age
young <- (tsne_df$Age.aggregated=='1-12') | (tsne_df$Age.aggregated=='1-5')
tsne_df$Age.aggregated[young] <- "under12"
tsne_df$Age.aggregated[!young] <- "All"

gg <- ggplot(tsne_df, aes(x=x, y=y, color=Age.aggregated)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw()
gg
```

We can investigate the ability of the different variables to predict the country of origin of an isolate. We make use of multinomial logistic regression with cross validation to assess the ability of each variable to distguish between the different countries.

```{r}
mod1.cv <- cv.glmnet(data.matrix(tsne_df[,c("x", "y")]), as.vector(tsne_df$Country), family="multinomial", type.measure = "class")
tsne.error <- mod1.cv$cvm[mod1.cv$lambda.min==mod1.cv$lambda]

x <- model.matrix(Country ~ Disease_Status, tsne_df)
mod2.cv <- cv.glmnet(x, as.vector(tsne_df$Country), family="multinomial", type.measure = "class")
disease.status.error <- mod2.cv$cvm[mod2.cv$lambda.min==mod2.cv$lambda]

x <- model.matrix(Country ~ Age.aggregated, tsne_df)
mod2.cv <- cv.glmnet(x, as.vector(tsne_df$Country), family="multinomial", type.measure = "class")
age.error <- mod2.cv$cvm[mod2.cv$lambda.min==mod2.cv$lambda]

x <- model.matrix(Country ~ num_types, tsne_df)
mod2.cv <- cv.glmnet(x, as.vector(tsne_df$Country), family="multinomial", type.measure = "class")
num.types.error <- mod2.cv$cvm[mod2.cv$lambda.min==mod2.cv$lambda]

plot.df <- data.frame(`Predicition Variable`=c("tSNE 2D", "Disease Status", "Age", "# Unique VAR Types"),
                      `Misclassification Error`=c(tsne.error, disease.status.error, age.error, num.types.error),
                      stringsAsFactors = FALSE)

ggplot(plot.df, aes(x=`Predicition.Variable`, y=`Misclassification.Error`)) + geom_col() + 
  theme_bw() + xlab("Prediction Variable") + ylab("Misclassification Error") +
  theme(text = element_text(size=15)) 
```

We can also colour by the number of types to investigate the impact of multiple infections

```{r}
tsne_df$num_types_range <- cut(tsne_df$num_types, c(0,40,80,120,300))
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country, shape=num_types_range)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw() + scale_shape_discrete(name="# Unique VAR Types")
gg
```

We can also investigate disease status.

```{r}
tsne_df$Disease_Status[tsne_df$Disease_Status==""] <- "Unknown"
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country, shape=Disease_Status)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw() + scale_shape_discrete(name="Disease Status")
gg
```

We can also investigate age.

```{r}
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country, shape=Age.aggregated)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca$Country))])
gg <- gg + theme_bw() + scale_shape_discrete(name="Age Category")
gg
```

We can also investigate the most conserved DBLa types. First lets look at a histogram of the number of times each DBLa is seen in the global population.
```{r}
plot.df <- data.frame(isolate=rownames(otuMatrixNoLab), 
                      occurence.count=rowSums(otuMatrixNoLab), 
                      stringsAsFactors = FALSE)
ggplot(plot.df, aes(x=occurence.count)) + 
  geom_histogram(bins = 50) +
  scale_y_sqrt() + theme_bw() +
  xlab("Count of Individual Type in the Data Set") + 
  ylab("Number of Unique Types")
```

This suggests that the majority of types are seen less than 20 times. We now take a closer look at those seen at least 20 times.
```{r}
majorTypeMatrix <- otuMatrixNoLab[rowSums(otuMatrixNoLab)>=20,]
col_annotations <- data.frame(Isolate = colnames(majorTypeMatrix),
                              stringsAsFactors = FALSE)
col_annotations <- merge(col_annotations, isolateInformation,
                         by.x="Isolate", by.y="Isolate",
                         all.x=TRUE)
rownames(col_annotations) <- col_annotations$Isolate
col_annotations <- col_annotations[, c("Isolate","Country")]
col_annotations <- col_annotations[order(col_annotations$Country),]
majorTypeMatrix <- majorTypeMatrix[, match(col_annotations$Isolate, colnames(majorTypeMatrix))]
col_annotations$Isolate <- NULL
pheatmap(majorTypeMatrix, cluster_cols = FALSE
         , annotation_col = col_annotations
         , show_rownames = FALSE
         , fontsize_row=2
         , show_colnames = FALSE)

sum(majorTypeMatrix[grepl("UG10689", rownames(majorTypeMatrix)),])
```

There are also a number of types that are very conserved. We now look closer at those seen more than 50 times. We first BLAST the resulting 100 most conserved sequences again NCBI BLAST nucleotide database and manually curate the hits with additional information after filtering based on a pairwise identity of 96% and a coverage threshold of 95%. Additionally we BLAST (megablast 2.2.18) against the var1, var2csa and var3 gene references from Rask et al.

```{bash, eval=FALSE}
makeblastdb -dbtype nucl -in ./data/var123_rask2010.fasta -out ./processed_data/blastdb_var123
megablast -m 8 -e 10 -i ./processed_data/majorTypesGE50.fasta -o ./processed_data/blast_var123_vs_majorTyepGE50.txt -d ./processed_data/blastdb_var123
```


```{r}
majorTypeMatrix <- otuMatrixNoLab[rowSums(otuMatrixNoLab)>=50,]

#Use diametric distance as described in xx
diametric_dist <- function(x,y){
  1-cor(x, y, method="pearson")^2
}
distMatrix <- proxy::dist(majorTypeMatrix, diametric_dist)

#We now perform some messy manipulations to annotate the heatmap.
col_annotations <- data.frame(Isolate = colnames(majorTypeMatrix),
                              stringsAsFactors = FALSE)
col_annotations <- merge(col_annotations, isolateInformation,
                         by.x="Isolate", by.y="Isolate",
                         all.x=TRUE)
rownames(col_annotations) <- col_annotations$Isolate
col_annotations <- col_annotations[, c("Isolate","Country")]
sort_order <- c("Uganda","Ghana","Gabon","Iran","Thailand","PNG","Peru","FrenchGuiana","Colombia","Venezuela")
col_annotations <- col_annotations[order(match(col_annotations$Country,sort_order)),]
majorTypeMatrix <- majorTypeMatrix[, match(col_annotations$Isolate, colnames(majorTypeMatrix))]
col_annotations$Isolate <- NULL

#Load manually curated annotation data
annotation_row <- fread("./processed_data/blast_hits_g50_summary_for_heatmap.txt",
                       data.table = FALSE,
                       sep="\t",
                       header=TRUE)
type_freq_df_anno <- type_freq_df
type_freq_df_anno$domain <- gsub("\\..*","", type_freq_df_anno$domain)
type_freq_df_anno <- type_freq_df_anno[,c("otu","domain")]

annotation_row <- merge(annotation_row, type_freq_df_anno
                        , by.x="SeqID", by.y="otu", all.x=TRUE)

annotation_row$Countries <- unlist(lapply(str_split(str_to_lower(paste(annotation_row$Countries_binary
                , annotation_row$Countries_blast, sep=";"))
               , pattern = ";")
               , function(x){paste(unique(x), collapse = ";")}) )
annotation_row <- annotation_row[match(rownames(majorTypeMatrix), annotation_row$SeqID),]
rownames(majorTypeMatrix) <- annotation_row$shortID #paste(annotation_row$shortID, annotation_row$Countries, sep="-")
annotation_row <- data.frame(row.names = rownames(majorTypeMatrix),
                             Annotation = annotation_row$Annotation,
                             DomainType = annotation_row$domain,
                             stringsAsFactors = FALSE)
annotation_row$Annotation <- NULL


# Specify colors
ann_colors = list(
    Country = c(Peru="#e31a1c", Gabon="#b2df8a", Colombia="#a6cee3",
                FrenchGuiana="#1f78b4", Iran="#fb9a99",
                Thailand="#ff7f00", Ghana="#33a02c", PNG="#fdbf6f",
                Uganda="#cab2d6", Venezuela="#6a3d9a"),
    Annotation = c(none = "#7fc97f", pseudo = "#beaed4"
                   , var1 = "#fdc086", FCR3var2="#ffff99"
                   , var5="#386cb0", FCR3var3="#f0027f"),
    DomainType = c(DBLa0="#ef8a62",DBLa1="#f7f7f7",DBLa2="#67a9cf")
)
pheatmap(majorTypeMatrix, cluster_cols = FALSE
         , clustering_distance_rows=distMatrix
         , annotation_col = col_annotations
         , annotation_row = annotation_row
         , show_rownames = TRUE
         , fontsize_row=4
         , show_colnames = FALSE
         , annotation_colors=ann_colors
         , treeheight_row = 0)

occurence_table <- data.frame(Isolate=rownames(annotation_row), total=rowSums(majorTypeMatrix), stringsAsFactors = FALSE)
occurence_table <- merge(occurence_table, annotation_row, by.x="Isolate", by.y=0)
occurence_table <- occurence_table[order(-occurence_table$total),]

write.table(rownames(majorTypeMatrix), file="./processed_data/majorTypesGE50.txt"
            , quote = FALSE
            , row.names = FALSE
            , col.names = FALSE)
```

We can also look at a table of the types seen most.
```{r}
kable(occurence_table)
```

```{bash, eval=FALSE}
blastn -perc_identity 96 -query ./majorTypesGE50.fasta -evalue 10 -outfmt '6 qseqid sseqid qlen length nident pident evalue bitscore salltitles'  -db nt -remote -out blastNTsearch.txt
```

#Run Admixture
Set up the required input file
```{r, eval=FALSE}
admixOut <- data.frame(family=rownames(otuMatrixNoLab_t),
                       individual=rownames(otuMatrixNoLab_t),
                       paternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       maternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       sex=rep(0, nrow(otuMatrixNoLab_t)),
                       phenotype=rep(-9, nrow(otuMatrixNoLab_t)))

#replicate each column
rep_otuMatrixNoLab_t <- otuMatrixNoLab_t[,rep(1:ncol(otuMatrixNoLab_t), rep(2,ncol(otuMatrixNoLab_t)))]
admixOut <- cbind(admixOut, apply(rep_otuMatrixNoLab_t, 2, function(x) x+1))
write.table(admixOut, file="./processed_data/admixture_input.ped"
            , quote=FALSE, sep=" "
            , row.names = FALSE, col.names=FALSE)

map <- data.frame(chromosome=rep(1,ncol(otuMatrixNoLab_t)),
                  id=paste(rep("rs", ncol(otuMatrixNoLab_t))
                           ,1:ncol(otuMatrixNoLab_t),sep=""),
                  dist=rep(0,ncol(otuMatrixNoLab_t)),
                  loc=11:(ncol(otuMatrixNoLab_t)+10),

                  stringsAsFactors = FALSE)
write.table(map, file="./processed_data/admixture_input.map"
            , quote=FALSE, sep="\t"
            , row.names = FALSE, col.names=FALSE)
```

Run Admixture v1.3 for different K
```{bash, eval=FALSE}
cd ./processed_data/
for K in {1..10};
do
admixture  -s 12345 -j20 --haploid="*" --cv ./admixture_input.ped $K | tee log${K}.out;
done
cd ..
```

Investigate the output of Admixture. First we need to load in the results.
```{r}
q_files <- Sys.glob("./processed_data/*.Q")
p_files <- Sys.glob("./processed_data/*.P")
log_files <- Sys.glob("./processed_data/log*.out")

admix <- admixList(
  mapply(loadAdmixture, q_files, p_files, log_files, SIMPLIFY = FALSE)
)

populations <- data.frame(Isolate=rownames(otuMatrixNoLab_t),
                          stringsAsFactors = FALSE)
populations <- merge(populations, isolateInformation,
                     by.x="Isolate", by.y="Isolate", all.x=TRUE)
populations <- populations[,c("Isolate", "Country")]
populations <- populations[match(rownames(otuMatrixNoLab_t), populations$Isolate),]
populations$Isolate <- 1:nrow(populations)
```

A quick look at the outcome of the cross validation method.
```{r}
bestK(admix)
plot.df <- bestK(admix, plot = FALSE)
ggplot(plot.df, aes(x=K, y=CVerror)) + geom_point(size=7) +
  theme_bw() + xlab("K") + ylab("Cross Validation Error") +
  theme(text = element_text(size=17)) 
```

This indicates that with two hidden populations we produce the smallest cross validation error. This split is consistent with the split between the African and non-African isolates. The large seperation between Africa and non-Africa is consistent with what has been seen in non-VAR population structure analyses and is also usually observed in analyses of human population structure. Lets look at this split.

```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==2][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

It is also worth taking a look at the K from 1 to 10
```{r}
plotMultiK(admix[order(unlist(lapply(admix,getK)))], populations)
```

The small dip in the cross-validation error at K=6 appears to correspond with Admixture infering different hidden populations for the three African countries. At K=6 Iran is also distinct. For all K PNG does is not seperated from the African background cluster. This could be because of the different experimental method used in obtaining the PNG isolates.

We now take a closer look at the model with 6 underlying populations.
```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==6][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

Finally it is worth looking closer at a model with 10 underlying populations. That is the same number as the real number of countries present.

```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==10][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

A notable difference between K=6 and K=10 is that for K=6 Columbia appears to be very much within the African background cluster 2 whilst for K=10 cluster 7 indicates that Columbia is distinct from the vast majority of African isolates.

It should be noted that these mixtures are built off of the binary dataset which ignores any relationship between DBLa types that are only present once. Consequently, the JHMM model approach is more appropriate.

##RAxML
First we need to produce a binary fasta file
```{r, eval=FALSE}
text=ggplot2:::interleave(paste(">", rownames(otuMatrixNoLab_t), sep=""),
                          apply(otuMatrixNoLab_t, 1 , paste , collapse = "" ))
writeLines(text, con="./processed_data/DBLa_binary.fasta",
           sep="\n")
```

Now we can run RAxML

```{bash, eval=FALSE}
cd ./processed_data/
~/standard-RAxML-8.2.8/raxmlHPC-PTHREADS -m BINCAT -p 12345 -s DBLa_binary.fasta -n raxmlTree_T1 -T 20 | tee raxml.log
cd ..
```

We can now look at the output of RAxML.
```{r}
raxml <- read.tree("./processed_data/RAxML_result.raxmlTree_T1")

groupInfo <- isolateInformation %>% group_by(Country) %>%
  do(taxa_list = .$Isolate)
groupInfo <- groupInfo[!(groupInfo$Country %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2")),]

groups <- lapply(groupInfo$taxa_list, as.vector)
names(groups) <- groupInfo$Country
raxml <- groupOTU(raxml, groups)

gg <- ggtree(raxml, aes(color=group, label=node)
             , size=0.3, branch.length = "none", layout="circular")
gg <- gg + scale_color_manual(values=cols,
                              labels=names(groups)) +
  theme(legend.position="right")
gg
```

Lets check quickly how the Ugandan samples have clustered (doesnt appear interesting, do I include this?)
```{r}
raxml <- read.tree("./processed_data/RAxML_result.raxmlTree_T1")

tempInfo <- isolateInformation
tempInfo$Location[!grepl("Uganda", tempInfo$Location)] <- "Other"

groupInfo <- tempInfo %>% group_by(Location) %>%
  do(taxa_list = .$Isolate)
groupInfo <- groupInfo[!(groupInfo$Location %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2")),]

groups <- lapply(groupInfo$taxa_list, as.vector)
names(groups) <- groupInfo$Location
raxml <- groupOTU(raxml, groups)

gg <- ggtree(raxml, aes(color=group, label=node)
             , size=0.3, branch.length = "none", layout="circular")
gg <- gg + scale_color_manual(values=cols,
                              labels=names(groups)) +
  theme(legend.position="right")
gg
```

##Alignment free comparison with FFP

First we need to split the sequences into seperate fasta files for each isolate
```{bash, eval=FALSE}
mkdir ffp_data
cd ffp_data
cp ../processed_data/combined_454_tessema.fas ./
cd ..
```

```{python, eval=FALSE}
from mungo.fasta import FastaReader
from collections import defaultdict

isolates = defaultdict(list)

for h,s in FastaReader("./processed_data/combined_454_tessema.fas"):
  isolates[h.split(".")[0]].append((h,s))

for iso in isolates:
  with open("./processed_data/"+iso+".fasta",'w') as outfile:
    for s in isolates[iso]:
      outfile.write(">"+s[0]+"\n"+s[1]+"\n")
```

We would now like to decide on an appropriate choice for the l-mer length. To investigate this we use the centroids after clustering the 3D7 isolate reads as a reference.
```{bash, eval=FALSE}
cd ffp_data
python ../scripts/clusterDBLa.py -o ./ -r 3D7.fasta

#Construct a word usage (vocabulary) profile
ffpvprof -e 40 -f 2 3D7_renamed_centroids.fasta > ../processed_data/ffp_word_usage.txt

#Construct a relative entropy profile
ffpreprof -e 40 3D7_renamed_centroids.fasta > ../processed_data/ffp_entropy_profile.txt

#We no longer need the lab isolates and can remove them
rm *3D7*.fasta
rm *DD2*.fasta
rm *HB3*.fasta

cd ..
```

We can now attempt to choose an appropriate value of l. First let look at word usage to get an idea of a lower bound.
```{r}
word_usage <- fread("./processed_data/ffp_word_usage.txt",
                    data.table = FALSE)
ggplot(word_usage, aes(x=V1, y=V2)) + geom_point() +
  theme_bw() + 
  xlab("k-mer feature length") +
  ylab("k-mer vocabulary size") +
  theme(text = element_text(size=15))
```

```{r}
entropy <- fread("./processed_data/ffp_entropy_profile.txt",
                    data.table = FALSE)
ggplot(entropy, aes(x=V1, y=V2)) + geom_point() +
  theme_bw() + 
  xlab("k-mer feature length") +
  ylab("cumlative relative entropy") +
  theme(text = element_text(size=15))
```

Thus a choice of l=20 appears to be appropriate.

We now want to get the set of sequences (excluding the labratory isolates) from which to cluster. We borrow those set up for the jumping HMM analysis (see supplementary_methods_2).

We can now run a script to calculate the ffp distance matrix. The original ffp script from xxx generated segment faults when we attempted to use it.
```{bash, eval=FALSE}
python ./scripts/ffp.py --kmer_length 20 --out ./processed_data/ffp_distance_matrix.phylip --seq ./processed_data/combined_454_tessema.fas --verbose
```

Finally a tree was built using fastme v2.1.4 with default parameters in interactive mode. We can now have a look at the resulting tree.

```{r}
ffp <- read.tree("./processed_data/ffp_distance_matrix.phylip_fastme_tree.txt")

isolateInformation$Country[isolateInformation$Country %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2")] <- "Lab"
isolateInformation <- isolateInformation[isolateInformation$Country!="Lab",]
groupInfo <- isolateInformation %>% group_by(Country) %>%
  do(taxa_list = .$Isolate)

groups <- lapply(groupInfo$taxa_list, as.vector)
names(groups) <- groupInfo$Country
ffp <- groupOTU(ffp, groups)

t_cols <- cols
names(t_cols) <- names(groups)

gg <- ggtree(ffp, aes(color=group, label=node)
             , size=0.3, branch.length = "none", layout="circular")
gg <- gg + scale_color_manual(values=as.character(t_cols[names(t_cols) %in% names(groups)]),
                              labels=names(t_cols)) +
  theme(legend.position="right")
gg
```

In a similar fashion to Yalcindag et al we remove the Peruvian and Venezulan isolates.
```{r, eval=FALSE}
distMatrix <- fread("./processed_data/ffp_distance_matrix.phylip", skip=1, header=FALSE, data.table = FALSE)

keep <- isolateInformation$Isolate[!(isolateInformation$Country %in% c("Peru", "Venezuela"))]
keep <- distMatrix$V1 %in% keep
distMatrix <- distMatrix[keep, c(TRUE, keep)]

cat((ncol(distMatrix)-1), '\n',  file = "./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip")
write.table(format(distMatrix, digits=10)
            , file="./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip"
            , sep=" ", row.names = FALSE
            , col.names = FALSE, quote = FALSE, append = TRUE)
```

Plot the tree without Peru and Venezuela
```{r}
ffp <- read.tree("./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip_fastme_tree.txt")

isolateInformationNoPeruVen <- isolateInformation[!(isolateInformation$Country %in% c("Peru", "Venezuela")),]

groupInfo <- isolateInformationNoPeruVen %>% group_by(Country) %>%
  do(taxa_list = .$Isolate)

groups <- lapply(groupInfo$taxa_list, as.vector)
names(groups) <- groupInfo$Country
ffp <- groupOTU(ffp, groups)

gg <- ggtree(ffp, aes(color=group, label=node)
             , size=0.3, branch.length = "none", layout="circular")
gg <- gg + scale_color_manual(values=as.character(t_cols[names(t_cols) %in% names(groups)]),
                              labels=names(groups)) +
  theme(legend.position="right")
gg
```

##Investigating association with severe disease segments

```{python, eval=FALSE}
from mungo.fasta import FastaReader
import sys,os

sig_dbla_clusters = {}

with open("./data/severe_disease_segments_plos_bio_2018.txt", 'rU') as infile:
	infile.next()
	for line in infile:
		line = line.strip().split("\t")
		if "DBLa" in line[0]:
			sig_dbla_clusters[line[0]] = line[8].split(",")


seq_dict = {}
for h,s in FastaReader("./data/combined_segments_from_plos_bio_2018.fasta"):
	seq_dict[h] = s


with open("./data/sig_dbla_segment_clusters.fasta", 'w') as outfile:
	for clust in sig_dbla_clusters:
		for seq in sig_dbla_clusters[clust]:
			outfile.write(">" + clust + "\n")
			outfile.write(seq_dict[seq] + "\n")
```

```{bash, eval=FALSE}
usearch -usearch_global ./data/sig_dbla_segment_clusters.fasta -db ./processed_data/combined_454_tessema_renamed_centroids_Protein.fasta -id 0.96 -blast6out ./processed_data/severe_var_plosbio2018_blast6out.txt -maxaccepts 0 -maxrejects 0
```

Appears only a small number of isolates from PNG include sequences from the severe data set. However these matched a region of the PNG sequences that is not present in the other data sets as the PNG data set was generated using Sanger sequencing. As we are only considering a small portion of the DBLa domain most of the other significant segments could not be searched for.

```{r}
severe.search.results <- fread("./processed_data/severe_var_plosbio2018_blast6out.txt", data.table = FALSE)
unique(severe.search.results$V1)
unique(gsub("\\..*", "", severe.search.results$V2))
```

We can also search for the homology blocks of Rask et al 2010.

```{bash, eval=FALSE}
hmmsearch --domtblout ./processed_data/rask_block_search_domtblout.txt --domT 9.7 --nonull2 --nobias ./data/rask_blocks.hmm ./processed_data/combined_454_tessema_renamed_centroids_Protein.fasta > ./processed_data/hmmsearch.out
```

```{r}
hmmsearch <- read.table("./processed_data/rask_block_search_domtblout.txt", sep = "" , header = FALSE,
                     na.strings ="", stringsAsFactors= FALSE, comment.char = "#")
hmmsearch <- hmmsearch[hmmsearch$V4 %in% c("Rask_block_219", "Rask_block_582", "Rask_block_47",
                                           "Rask_block_142", "Rask_block_126", "Rask_block_97",
                                           "Rask_block_121", "Rask_block_141", "Rask_block_150",
                                           "Rask_block_150", "Rask_block_183"),]
length(unique(hmmsearch$V1))
```

##Session Information
```{r}
sessionInfo()
```
