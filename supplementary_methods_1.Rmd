---
title: "Suplementary methods"
author: "Gerry Tonkin-Hill"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 12
    fig_height: 8
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8,
                      echo=FALSE, warning=FALSE, message=FALSE,
                      tidy=TRUE)
```


##Load libraries

```{r}
library(data.table)
library(dplyr)
library(ggfortify)
library(ggplot2)
library(Rtsne)
library(flashpcaR)
library(stringr)

cols <- c("#a6cee3","#1f78b4","#b2df8a","#33a02c","#fb9a99","#e31a1c","#fdbf6f","#ff7f00","#cab2d6","#6a3d9a","#ffff99","#b15928","#8dd3c7","#ffffb3","#bebada","#fb8072","#80b1d3","#fdb462","#b3de69","#fccde5","#d9d9d9","#bc80bd","#ccebc5","#ffed6f")
```



##Otu Analysis
First we need to relabel the reads of Tessema et al to include isolate information for clustering.
```{python, eval = FALSE}
from mungo.fasta import FastaReader

read_to_isolate={}
with open("./data/read_info.csv", 'rU') as infile:
  infile.next()
  for line in infile:
    line=line.strip().split(",")
    read_to_isolate[line[0]]=line[1]

with open("./processed_data/tessema2015_renamed.fas", 'w') as outfile:
  for h,s in FastaReader("./data/tessema2015.fas"):
    outfile.write(">"+read_to_isolate[h]+"."+h+"\n"+s+"\n")
```

We start by clustering the raw 454 reads along with the reads from Tessema et al using a python script that makes use of the Usearch software suite.
```{bash, eval = FALSE}
cat ./data/combined_all_454_noPOR.fasta ./processed_data/tessema2015_renamed.fas > ./processed_data/combined_454_tessema.fas

python ~/clusterDBLa/clusterDBLa.py \
  -o ./processed_data/ \
  -r ./processed_data/combined_454_tessema.fas \
  --cpu 20
```

###Binary Analysis

Now we can investigate the isolates based on shared DBLa sequence types.

```{r}
isolateInformation <- fread("./data/isolate_information.csv"
                            , header=TRUE
                            , data.table = FALSE)
#Add in country information
isolateInformation$Country <- unlist(lapply(isolateInformation$Location
                                            , function(x) {
                                              str_split(x,  "_", n=2)[[1]][[1]]}))

#Remove duplicate entries of isolates that have been sequenced more than once
isolateInformation <- isolateInformation[!duplicated(isolateInformation$Isolate),]

otuTable <- fread("./processed_data/combined_454_tessema_renamed_otuTable_binary.txt"
                  , data.table = FALSE
                  , header=TRUE)

otuMatrix <- as.matrix(otuTable[,2:ncol(otuTable)])
rownames(otuMatrix) <- otuTable$`#OTU ID`
```

We next perform some filtering. We exclude the lab isolates and only investigate isolates that were found to have more than 20 DBLa types. This was found to be a sensible thresholf on having adequetly sequences an isolates VAR repetoir. Furthermore as we are interested in the realtionship between isolates we exclude the singletons from the binary analysis.
```{r}
#Filter otus that only appear in one isolate and isolates with less than 20 types
MIN_ISOLATE_PER_OTU = 2
MIN_OTUS_PER_ISOLATE = 20
MAX_OTUS_PER_ISOLATE = Inf
otuMatrix <- otuMatrix[, colSums(otuMatrix) >= MIN_OTUS_PER_ISOLATE]
otuMatrix <- otuMatrix[, colSums(otuMatrix) <= MAX_OTUS_PER_ISOLATE]
otuMatrix <- otuMatrix[rowSums(otuMatrix) >= MIN_ISOLATE_PER_OTU, ]

#Remove lab isolates
otuMatrixNoLab <- otuMatrix[,!(colnames(otuMatrix) %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2"))]
```

###PCA
```{r}
otuMatrixNoLab_t <- t(otuMatrixNoLab)

flash_pca <- flashpca(otuMatrixNoLab_t
                      , stand="binom", method="eigen"
                      , ndim=50, mem="high")

pca_df <- data.frame(Isolate = rownames(otuMatrixNoLab_t)
                     , flash_pca$vectors[, 1:6]
                     , stringsAsFactors = FALSE)
pca_df <- merge(pca_df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

#PCA plot
gg <- ggplot(pca_df, aes(X1, X2, colour=Country)) + geom_point() 
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

###TSNE
```{r}
tsne <- Rtsne(flash_pca$vectors, perplexity=15
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne_df <- data.frame(Isolate=rownames(otuMatrixNoLab_t)
                      , x=tsne$Y[,1], y=tsne$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)
                      , stringsAsFactors = FALSE)
tsne_df <- merge(tsne_df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

We can also colour by the number of types to investigate the impact of multiple infections
```{r}
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country, alpha=num_types)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

We can also investigate disease status.

```{r}
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Disease_Status)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

Age doesn't appear to be an issue.

```{r}
gg <- ggplot(tsne_df, aes(x=x, y=y, color=Age)) + geom_point()
gg <- gg + scale_color_manual(values = cols[1:length(unique(pca_df$Country))])
gg <- gg + theme_bw()
gg
```

#Run Admixture
Set up the required input file
```{r, eval=FALSE}
admixOut <- data.frame(family=rownames(otuMatrixNoLab_t),
                       individual=rownames(otuMatrixNoLab_t),
                       paternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       maternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       sex=rep(0, nrow(otuMatrixNoLab_t)),
                       phenotype=rep(-9, nrow(otuMatrixNoLab_t)))
admixOut <- cbind(admixOut, apply(otuMatrixNoLab_t, 2, function(x) x+1))
write.table(admixOut, file="./processed_data/admixture_input.ped"
            , quote=FALSE, sep=" "
            , row.names = FALSE, col.names=FALSE)
```

Run Admixture v1.3 for different K
```{bash, eval=FALSE}
cd ./processed_data/
for K in {1..10};
do
admixture -s 12345 -j20 --cv ./admixture_input.ped $K | tee log${K}.out;
done
cd ..
```

##RAxML
First we need to produce a binary fasta file
```{r, eval=FALSE}
text=ggplot2:::interleave(paste(">", rownames(otuMatrixNoLab_t), sep=""),
                          apply(otuMatrixNoLab_t, 1 , paste , collapse = "" ))
writeLines(text, con="./processed_data/DBLa_binary.fasta",
           sep="\n")
```

Now we can run RAxML

```{bash, eval=FALSE}
cd ./processed_data/
~/standard-RAxML-8.2.8/raxmlHPC-PTHREADS -m BINCAT -p 12345 -s DBLa_binary.fasta -n raxmlTree_T1 -T 20 | tee raxml.log
cd ..
```

##Alignment free comparison with FFP

First we need to split the sequences into seperate fasta files for each isolate
```{bash, eval=FALSE}
mkdir ffp_data
cd ffp_data
cp ../processed_data/combined_454_tessema.fas ./
cd ..
```

```{python, eval=FALSE}
from mungo.fasta import FastaReader
from collections import defaultdict

isolates = defaultdict(list)

for h,s in FastaReader("./processed_data/combined_454_tessema.fas"):
  isolates[h.split(".")[0]].append((h,s))

for iso in isolates:
  with open("./processed_data/"+iso+".fasta",'w') as outfile:
    for s in isolates[iso]:
      outfile.write(">"+s[0]+"\n"+s[1]+"\n")
```

We would now like to decide on an appropriate choice for the l-mer length. To investigate this we use the centroids after clustering the 3D7 isolate reads as a reference.
```{bash, eval=FALSE}
cd ffp_data
python ../scripts/clusterDBLa.py -o ./ -r 3D7.fasta

#Construct a word usage (vocabulary) profile
ffpvprof -e 40 -f 2 3D7_renamed_centroids.fasta > ../processed_data/ffp_word_usage.txt

#Construct a relative entropy profile
ffpreprof -e 40 3D7_renamed_centroids.fasta > ../processed_data/ffp_entropy_profile.txt

#We no longer need the lab isolates and can remove them
rm *3D7*.fasta
rm *DD2*.fasta
rm *HB3*.fasta

cd ..
```

We can now attempt to choose an appropriate value of l. First let look at word usage to get an idea of a lower bound.
```{r}
word_usage <- fread("./processed_data/ffp_word_usage.txt",
                    data.table = FALSE)
plot(word_usage)
```

```{r}
entropy <- fread("./processed_data/ffp_entropy_profile.txt",
                    data.table = FALSE)
plot(entropy)
```

Thus a choice of l=20 appears to be appropriate.

We can now run the default FFP pipeline to obtain a distance matrix
```{bash, eval=FALSE}
cd ffp_data

ls *.fasta > species.txt
ffpry -m -l 20 *.fasta | ffpcol | ffprwn | ffpjsd -p species.txt > jensen_shannon_dist.phylip

cd ..
```

##Session Information
```{r}
sessionInfo()
```
