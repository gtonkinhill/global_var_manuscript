---
title: "Suplementary methods"
author: "Gerry Tonkin-Hill"
date: "`r Sys.Date()`"
output: 
  html_document:
    fig_width: 12
    fig_height: 8
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8,
                      echo=TRUE, warning=FALSE, message=FALSE,
                      tidy=TRUE)
```


##Load libraries

```{r}
library(data.table)
library(dplyr)
library(ggfortify)
library(ggplot2)
library(Rtsne)
library(stringr)
library(starmie)
library(ggtree)
library(ape)
library(pheatmap)
library(proxy)
library(knitr)
library(glmnet)
library(scales)

colscale <-  c("#a6cee3","#1f78b4","#b2df8a","#33a02c","#fb9a99","#e31a1c","#fdbf6f","#ff7f00","#cab2d6","#6a3d9a")
names(colscale) <- c("Colombia", "FrenchGuiana", "Gabon", "Ghana", "Iran", "Peru", "PNG", "Thailand", "Uganda", "Venezuela")
colScale <- scale_colour_manual(name = "Country",values = colscale)
fillScale <- scale_fill_manual(name = "Country",values = colscale)

set.seed(1234)
```



##Otu Analysis
First we need to relabel the reads of Tessema et al to include isolate information for clustering.
```{python, eval = FALSE}
from mungo.fasta import FastaReader

read_to_isolate={}
with open("./data/read_info.csv", 'rU') as infile:
  infile.next()
  for line in infile:
    line=line.strip().split(",")
    read_to_isolate[line[0]]=line[1]

with open("./processed_data/tessema2015_renamed.fas", 'w') as outfile:
  for h,s in FastaReader("./data/tessema2015.fas"):
    outfile.write(">"+read_to_isolate[h]+"."+h+"\n"+s+"\n")
```

We start by clustering the raw 454 reads along with the reads from Tessema et al using a python script that makes use of the Usearch software suite.

```{bash, eval = FALSE}
cat ./data/combined_all_454_noPOR.fasta ./processed_data/tessema2015_renamed.fas > ./processed_data/combined_454_tessema.fas

python ~/clusterDBLa/clusterDBLa.py \
  -o ./processed_data/ \
  -r ./processed_data/combined_454_tessema.fas \
  --cpu 20
```

###Binary Analysis

Now we can investigate the isolates based on shared DBLa sequence types.

```{r}
isolateInformation <- fread("./data/isolate_information.csv"
                            , header=TRUE
                            , data.table = FALSE)
#Add in country information
isolateInformation$Country <- unlist(lapply(isolateInformation$Location
                                            , function(x) {
                                              str_split(x,  "_", n=2)[[1]][[1]]}))

#Remove duplicate entries of isolates that have been sequenced more than once
isolateInformation <- isolateInformation[!duplicated(isolateInformation$Isolate),]

isolateInformation$Disease_Status[isolateInformation$Disease_Status==""] <- "Uncomplicated"

otuTable <- fread("./processed_data/combined_454_tessema_renamed_otuTable_binary.txt"
                  , data.table = FALSE
                  , header=TRUE)

otuMatrix <- as.matrix(otuTable[,2:ncol(otuTable)])
rownames(otuMatrix) <- otuTable$`#OTU ID`
```

We found a total of `r sum(otuMatrix)` reads in the combined dataset, which clustered into a total of `r nrow(otuMatrix)`. Of these `r sum(rowSums(otuMatrix)==1)` were only seen in one isolate.

Look  at the number of types conserved across multiple countries and continents

```{r}
otuMatrixNoLab <- otuMatrix[,!(colnames(otuMatrix) %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2"))]
otuMatrixNoLab <- otuMatrixNoLab[rowSums(otuMatrixNoLab) >= 1, ]

temp <- rowsum(t(otuMatrixNoLab), 
       group = isolateInformation$Country[match(colnames(otuMatrixNoLab), 
                                                isolateInformation$Isolate)])

plot.df <- data.frame(Isolate=colnames(temp), 
                      num_observed=colSums(temp),
                      num_countries=colSums(temp>0), stringsAsFactors = FALSE)

ggplot(plot.df, aes(x=num_observed, y=num_countries)) +
  geom_jitter(width = 0, height = 0.2) +
  theme_bw() + ylab("Number of countries with gene")  +
  xlab("Number of isolates with gene") +
  scale_y_continuous(breaks=1:10) + 
  theme(text = element_text(size=14))

num_countries <- colSums(rowsum(t(otuMatrixNoLab), 
       group = isolateInformation$Country[match(colnames(otuMatrixNoLab), 
                                                isolateInformation$Isolate)])>0)
table(num_countries)
plot.df <- data.frame(Type=names(num_countries),
                      country.count=num_countries, stringsAsFactors = FALSE)
ggplot(plot.df, aes(x=country.count)) + geom_bar() +
  scale_y_log10() +
  xlab("Number of Countries") +
  scale_x_continuous(breaks=1:10) + 
  theme_bw() +
  theme(text = element_text(size=14)) +
  ylab("Number of DBLa types")

temp.continents <- isolateInformation$Country
temp.continents[temp.continents %in% c("Colombia","FrenchGuiana","Peru","Venezuela")] <- "S.America"
temp.continents[temp.continents %in% c("Ghana","Gabon","Uganda")] <- "Africa"
temp.continents[temp.continents %in% c("Iran","PNG","Thailand")] <- "Asia"
conserved.counts.by.continent <- colSums(rowsum(t(otuMatrixNoLab), 
                                        temp.continents[match(colnames(otuMatrixNoLab),
                                                              isolateInformation$Isolate)])>0)
table(conserved.counts.by.continent)
plot.df <- data.frame(Type=names(conserved.counts.by.continent),
                      continent.count=conserved.counts.by.continent, stringsAsFactors = FALSE)
ggplot(plot.df, aes(x=continent.count)) + geom_bar() +
  scale_y_log10() + 
  xlab("Number of Continents") +
  scale_x_continuous(breaks=1:3) + 
  theme_bw() +
  ylab("Number of DBLa types")
```


We next perform some filtering. We exclude the lab isolates and only investigate isolates that were found to have more than 20 DBLa types. This was found to be a sensible thresholf on having adequetly sequences an isolates VAR repetoir. Furthermore as we are interested in the relationship between isolates we exclude the singletons from the binary analysis.
```{r}
#Filter otus that only appear in one isolate and isolates with less than 20 types
MIN_ISOLATE_PER_OTU = 1
MIN_OTUS_PER_ISOLATE = 2
MAX_OTUS_PER_ISOLATE = Inf
otuMatrix <- otuMatrix[, colSums(otuMatrix) >= MIN_OTUS_PER_ISOLATE]
otuMatrix <- otuMatrix[, colSums(otuMatrix) <= MAX_OTUS_PER_ISOLATE]

#Remove lab isolates
otuMatrixNoLab <- otuMatrix[,!(colnames(otuMatrix) %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2"))]
otuMatrixNoLab <- otuMatrixNoLab[rowSums(otuMatrixNoLab) >= MIN_ISOLATE_PER_OTU, ]
```

Identify which OTU centroids match with the 3D7 refernce for later infestigation.
```{bash, eval=FALSE}
usearch -usearch_global ./data/3D7.fasta -db ./data/combined_all_454_noPOR.fasta -id 0.96 -strand both -blast6out ./processed_data/3D7_vs_all_blast6out.txt -maxaccepts 0 -maxrejects 0
```

```{r}
otu_match_3D7 <- unique(fread("./processed_data/3D7_vs_all_blast6out.txt", data.table = FALSE)[,2])
```

We can now look at the number of reads per isolate for the different countries.
```{r}
otu_sums <- data.frame(Isolate=colnames(otuMatrixNoLab), num_otus=colSums(otuMatrixNoLab)
                       , stringsAsFactors = FALSE)
  
otu_sums <- merge(otu_sums, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

median_summary <- otu_sums %>% group_by(Country) %>% 
  summarise(n=n(),
            median=median(num_otus),
            max=max(num_otus))
  
#boxplot plot 
gg <- ggplot(otu_sums, aes(Country, num_otus, fill=Country)) + geom_boxplot()
gg <- gg + fillScale
gg <- gg + theme_bw() + ylab("number of DBLa types")
gg
```

We can also compare the number of type A and type B/C VAR genes.
```{bash, eval=FALSE}
python ./scripts/allocate_reads_to_domains.py --fasta ./processed_data/combined_454_tessema_renamed_centroids.fasta --hmm ./data/all_protein_exon1_domain_HMMs.hmm --out_dir ./processed_data/
```

```{r}
type_freq_df <- data.frame(otu=rownames(otuMatrixNoLab)
                           , num_isolates=rowSums(otuMatrixNoLab)
                           , stringsAsFactors = FALSE)
type_allocations <- fread("./processed_data/combined_454_tessema_renamed_centroids_domainAllocations.csv", sep=",", header=TRUE, data.table = FALSE)
type_allocations$read <- gsub(";sample.*", "", type_allocations$read)
type_freq_df <- merge(type_freq_df, type_allocations
                      ,by.x = "otu", by.y="read", all.x=TRUE)
type_freq_df$type[grepl("DBLa1", type_freq_df$domain)] <- "A"
type_freq_df$type[!grepl("DBLa1", type_freq_df$domain)] <- "B/C"

#Count number of each type
type_freq_df %>% group_by(type) %>%
  summarise(
    total=sum(num_isolates)
  )

#Remove rares
type_freq_df <- type_freq_df[type_freq_df$num_isolates>1,]

#boxplot
gg <- ggplot(type_freq_df, aes(factor(type), num_isolates, fill=type)) + geom_boxplot()
gg <- gg + theme_bw()
gg <- gg + scale_y_log10() + ylab("number of DBLa types")
gg
```

###PCA
```{r}
otuMatrixNoLab_t <- t(otuMatrixNoLab)

pca <- prcomp(otuMatrixNoLab_t)

pca <- data.frame(Isolate = rownames(otuMatrixNoLab_t)
                     , pca$x[, 1:6]
                     , stringsAsFactors = FALSE)

pca <- merge(pca, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

#PCA plot
gg <- ggplot(pca, aes(PC1, PC2, colour=Country)) + geom_point() 
gg <- gg + colScale
gg <- gg + theme_bw()
gg
```

Also worth looking at the 3rd and 4th principal components that appear to split mainly on the different African countries.
```{r}
#PCA plot
gg <- ggplot(pca, aes(PC3, PC4, colour=Country)) + geom_point() 
gg <- gg  + colScale
gg <- gg + theme_bw()
gg
```


###TSNE
```{r}
pca_tsne <- prcomp(otuMatrixNoLab_t, scale. = TRUE)

tsne <- Rtsne(pca_tsne$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne_df <- data.frame(Isolate=rownames(otuMatrixNoLab_t)
                      , x=tsne$Y[,1], y=tsne$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)
                      , stringsAsFactors = FALSE)
tsne_df <- merge(tsne_df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne_df, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + colScale 
gg <- gg + theme_bw()
gg <- gg + xlab("tSNE dimension 1") + ylab("tSNE dimension 2")
gg
```

Check the impact of ignoring types found in 3D7
```{r}
pca_tsne2 <- prcomp(otuMatrixNoLab_t[,!(colnames(otuMatrixNoLab_t) %in% otu_match_3D7)], scale. = TRUE)

tsne2 <- Rtsne(pca_tsne2$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne_df2 <- data.frame(Isolate=rownames(otuMatrixNoLab_t)
                      , x=tsne2$Y[,1], y=tsne2$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)
                      , stringsAsFactors = FALSE)
tsne_df2 <- merge(tsne_df2, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne_df2, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + colScale
gg <- gg + theme_bw()
gg
```

Investigate the impact of possible cofounders. As some datasets were collected from uncomplicated cases whilst others were collected from asymptomatic cases we can not completely rule out an impact of differences in disease status. However, the overiding clustering appears to be due to geography as after restricting to datasets of the same disease status isolates remained clustered by country.

First the uncomplicated cases

```{r}
keep <- rownames(otuMatrixNoLab_t) %in% tsne_df2$Isolate[tsne_df2$Disease_Status=="Uncomplicated"]
otu.subset <- otuMatrixNoLab_t[keep,]
otu.subset <- otu.subset[,colSums(otu.subset)>0]
pca_tsne.uncom <- prcomp(otu.subset, scale. = TRUE)

tsne.uncom <- Rtsne(pca_tsne.uncom$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne.uncom.df <- data.frame(Isolate=rownames(otuMatrixNoLab_t)[keep]
                      , x=tsne.uncom$Y[,1], y=tsne.uncom$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)[keep]
                      , stringsAsFactors = FALSE)
tsne.uncom.df <- merge(tsne.uncom.df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne.uncom.df, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + colScale
gg <- gg + theme_bw()
gg <- gg + xlab("tSNE dimension 1") + ylab("tSNE dimension 2")
gg
```

Now the asymptomatic

```{r}
keep <- rownames(otuMatrixNoLab_t) %in% tsne_df2$Isolate[tsne_df2$Disease_Status!="Uncomplicated"]
otu.subset <- otuMatrixNoLab_t[keep,]
otu.subset <- otu.subset[,colSums(otu.subset)>0]
pca_tsne.asym <- prcomp(otu.subset, scale. = TRUE)
tsne.asym <- Rtsne(pca_tsne.asym$x[,1:30], perplexity=10
              , check_duplicates=FALSE, pca=FALSE
              , max_iter=1000, dims = 2)

tsne.asym.df <- data.frame(Isolate=rownames(otuMatrixNoLab_t)[keep]
                      , x=tsne.asym$Y[,1], y=tsne.asym$Y[,2]
                      , num_types =rowSums(otuMatrixNoLab_t)[keep]
                      , stringsAsFactors = FALSE)
tsne.asym.df <- merge(tsne.asym.df, isolateInformation, by.x='Isolate', by.y='Isolate'
                , all.x=TRUE)

gg <- ggplot(tsne.asym.df, aes(x=x, y=y, color=Country)) + geom_point()
gg <- gg + colScale
gg <- gg + theme_bw()
gg <- gg + xlab("tSNE dimension 1") + ylab("tSNE dimension 2")
gg
```

This indicates that the number of types does not distguish countries more effectively than the tsne dimensions which are based on the types themselves.


We can also investigate the most conserved DBLa types. First lets look at a histogram of the number of times each DBLa is seen in the global population.

```{r}
plot.df <- data.frame(isolate=rownames(otuMatrixNoLab), 
                      occurence.count=rowSums(otuMatrixNoLab), 
                      stringsAsFactors = FALSE)
ggplot(plot.df, aes(x=occurence.count)) + 
  geom_histogram(bins = 50) +
  scale_y_sqrt(breaks=c(100,1000,3000,6000,9000),expand = c(0, 0)) + theme_bw() +
  scale_x_continuous(expand = c(0, 0)) +
  xlab("Count of Individual Type in the Data Set") + 
  ylab("Number of Unique Types")
```

This suggests that the majority of types are seen less than 20 times. We now take a closer look at those seen at least 20 times.
```{r}
majorTypeMatrix <- otuMatrixNoLab[rowSums(otuMatrixNoLab)>=20,]
col_annotations <- data.frame(Isolate = colnames(majorTypeMatrix),
                              stringsAsFactors = FALSE)
col_annotations <- merge(col_annotations, isolateInformation,
                         by.x="Isolate", by.y="Isolate",
                         all.x=TRUE)
rownames(col_annotations) <- col_annotations$Isolate
col_annotations <- col_annotations[, c("Isolate","Country")]
col_annotations <- col_annotations[order(col_annotations$Country),]
majorTypeMatrix <- majorTypeMatrix[, match(col_annotations$Isolate, colnames(majorTypeMatrix))]
col_annotations$Isolate <- NULL
pheatmap(majorTypeMatrix, cluster_cols = FALSE
         , annotation_col = col_annotations
         , show_rownames = FALSE
         , fontsize_row=2
         , show_colnames = FALSE)

```

There are also a number of types that are very conserved. We now look closer at those seen more than 50 times. We first BLAST the resulting 100 most conserved sequences again NCBI BLAST nucleotide database and manually curate the hits with additional information after filtering based on a pairwise identity of 96% and a coverage threshold of 95%. Additionally we BLAST (megablast 2.2.18) against the var1, var2csa and var3 gene references from Rask et al.

```{bash, eval=FALSE}
makeblastdb -dbtype nucl -in ./data/var123_rask2010.fasta -out ./processed_data/blastdb_var123
megablast -m 8 -e 10 -i ./processed_data/majorTypesGE50.fasta -o ./processed_data/blast_var123_vs_majorTyepGE50.txt -d ./processed_data/blastdb_var123
```


```{r}
majorTypeMatrix <- otuMatrixNoLab[rowSums(otuMatrixNoLab)>=50,]

#Use diametric distance as described in xx
diametric_dist <- function(x,y){
  1-cor(x, y, method="pearson")^2
}
distMatrix <- proxy::dist(majorTypeMatrix, diametric_dist)

#We now perform some messy manipulations to annotate the heatmap.
col_annotations <- data.frame(Isolate = colnames(majorTypeMatrix),
                              stringsAsFactors = FALSE)
col_annotations <- merge(col_annotations, isolateInformation,
                         by.x="Isolate", by.y="Isolate",
                         all.x=TRUE)
rownames(col_annotations) <- col_annotations$Isolate
col_annotations <- col_annotations[, c("Isolate","Country")]
sort_order <- c("Uganda","Ghana","Gabon","Iran","Thailand","PNG","Peru","FrenchGuiana","Colombia","Venezuela")
col_annotations <- col_annotations[order(match(col_annotations$Country,sort_order)),]
majorTypeMatrix <- majorTypeMatrix[, match(col_annotations$Isolate, colnames(majorTypeMatrix))]
col_annotations$Isolate <- NULL

#Load manually curated annotation data
annotation_row <- fread("./processed_data/blast_hits_g50_summary_for_heatmap.txt",
                       data.table = FALSE,
                       sep="\t",
                       header=TRUE)
type_freq_df_anno <- type_freq_df
type_freq_df_anno$domain <- gsub("\\..*","", type_freq_df_anno$domain)
type_freq_df_anno <- type_freq_df_anno[,c("otu","domain")]

annotation_row <- merge(annotation_row, type_freq_df_anno
                        , by.x="SeqID", by.y="otu", all.x=TRUE)

annotation_row$Countries <- unlist(lapply(str_split(str_to_lower(paste(annotation_row$Countries_binary
                , annotation_row$Countries_blast, sep=";"))
               , pattern = ";")
               , function(x){paste(unique(x), collapse = ";")}) )
annotation_row <- annotation_row[match(rownames(majorTypeMatrix), annotation_row$SeqID),]
rownames(majorTypeMatrix) <- annotation_row$shortID #paste(annotation_row$shortID, annotation_row$Countries, sep="-")
annotation_row <- data.frame(row.names = rownames(majorTypeMatrix),
                             Annotation = annotation_row$Annotation,
                             DomainType = annotation_row$domain,
                             stringsAsFactors = FALSE)
annotation_row$Annotation <- NULL


# Specify colors
ann_colors = list(
    Country = colscale,
    Annotation = c(none = "#7fc97f", pseudo = "#beaed4"
                   , var1 = "#fdc086", FCR3var2="#ffff99"
                   , var5="#386cb0", FCR3var3="#f0027f"),
    DomainType = c(DBLa0="#ef8a62",DBLa1="#f7f7f7",DBLa2="#67a9cf")
)
pheatmap(majorTypeMatrix, cluster_cols = FALSE
         , clustering_distance_rows=distMatrix
         , annotation_col = col_annotations
         , annotation_row = annotation_row
         , show_rownames = TRUE
         , fontsize_row=4
         , show_colnames = FALSE
         , annotation_colors=ann_colors
         , treeheight_row = 0
         , color=c("#ffffff","#000000"))

occurence_table <- data.frame(Isolate=rownames(annotation_row), total=rowSums(majorTypeMatrix), stringsAsFactors = FALSE)
occurence_table <- merge(occurence_table, annotation_row, by.x="Isolate", by.y=0)
occurence_table <- occurence_table[order(-occurence_table$total),]

write.table(rownames(majorTypeMatrix), file="./processed_data/majorTypesGE50.txt"
            , quote = FALSE
            , row.names = FALSE
            , col.names = FALSE)
```

Look at distribution of types

```{r}
#Thos seen in Africa, S.America and Asia
temp.countries <- isolateInformation$Country[match(colnames(majorTypeMatrix), isolateInformation$Isolate)]
conserved.counts.by.country <- rowsum(t(majorTypeMatrix), temp.countries)
hist(colSums(conserved.counts.by.country>0), breaks = 10)

temp.continents <- temp.countries
temp.continents[temp.continents %in% c("Colombia","FrenchGuiana","Peru","Venezuela")] <- "S.America"
temp.continents[temp.continents %in% c("Ghana","Gabon","Uganda")] <- "Africa"
temp.continents[temp.continents %in% c("Iran","PNG","Thailand")] <- "Asia"
conserved.counts.by.continent <- rowsum(t(majorTypeMatrix), temp.continents)
sum(colSums(conserved.counts.by.country>0)==3)

most.common <- rownames(majorTypeMatrix)[which.max(rowSums(majorTypeMatrix))]
sum(conserved.counts.by.country[,most.common])
```

We can also look at a table of the types seen most.
```{r}
kable(occurence_table)
```

```{bash, eval=FALSE}
blastn -perc_identity 96 -query ./majorTypesGE50.fasta -evalue 10 -outfmt '6 qseqid sseqid qlen length nident pident evalue bitscore salltitles'  -db nt -remote -out blastNTsearch.txt
```

We can also search for these conserved types in the recent dataset of Otto et al., 2019.

```{python, eval=FALSE}
from mungo.fasta import FastaReader

c=0
with open("index.csv", 'w') as index:
    with open("renamed_varDB.fulldataset.1kb.nt.fasta", 'w') as outfile:
        for h,s in FastaReader("varDB.fulldataset.1kb.nt.fasta"):
                outfile.write(">"+str(c)+"\n"+s+"\n")
                index.write(str(c)+","+h.replace(","," ")+"\n")
                c+=1
```

```
makeblastdb -in renamed_varDB.fulldataset.1kb.nt.fasta -dbtype nucl -parse_seqids
blastn -db renamed_varDB.fulldataset.1kb.nt.fasta -query majorTypesGE50.fasta -out search_results.txt -outfmt 7 -evalue 1e-6 -num_threads 30
```

```{python, eval=FALSE}
index = {}
with open("index.csv", 'r') as indexfile:
  for line in indexfile:
    line=line.strip().split(",")
    index[line[0]] = line[1]

with open("search_results.txt", 'r') as infile:
  with open("conserved_var_vs_otto2019_search.txt", 'w') as outfile:
    for line in infile:
      if line[0]=="#": continue
      line = line.strip().split()
      line[1] = index[line[1]]
      outfile.write("\t".join(line)+"\n")
```

#Run Admixture
Set up the required input file
```{r, eval=FALSE}
admixOut <- data.frame(family=rownames(otuMatrixNoLab_t),
                       individual=rownames(otuMatrixNoLab_t),
                       paternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       maternalId=rep(0, nrow(otuMatrixNoLab_t)),
                       sex=rep(0, nrow(otuMatrixNoLab_t)),
                       phenotype=rep(-9, nrow(otuMatrixNoLab_t)))

#replicate each column
rep_otuMatrixNoLab_t <- otuMatrixNoLab_t[,rep(1:ncol(otuMatrixNoLab_t), rep(2,ncol(otuMatrixNoLab_t)))]
admixOut <- cbind(admixOut, apply(rep_otuMatrixNoLab_t, 2, function(x) x+1))
write.table(admixOut, file="./processed_data/admixture_input.ped"
            , quote=FALSE, sep=" "
            , row.names = FALSE, col.names=FALSE)

map <- data.frame(chromosome=rep(1,ncol(otuMatrixNoLab_t)),
                  id=paste(rep("rs", ncol(otuMatrixNoLab_t))
                           ,1:ncol(otuMatrixNoLab_t),sep=""),
                  dist=rep(0,ncol(otuMatrixNoLab_t)),
                  loc=11:(ncol(otuMatrixNoLab_t)+10),

                  stringsAsFactors = FALSE)
write.table(map, file="./processed_data/admixture_input.map"
            , quote=FALSE, sep="\t"
            , row.names = FALSE, col.names=FALSE)
```

Run Admixture v1.3 for different K
```{bash, eval=FALSE}
cd ./processed_data/
for K in {1..10};
do
admixture  -s 12345 -j20 --haploid="*" --cv ./admixture_input.ped $K | tee log${K}.out;
done
cd ..
```

Investigate the output of Admixture. First we need to load in the results.
```{r}
q_files <- Sys.glob("./processed_data/*.Q")
p_files <- Sys.glob("./processed_data/*.P")
log_files <- Sys.glob("./processed_data/log*.out")

admix <- admixList(
  mapply(loadAdmixture, q_files, p_files, log_files, SIMPLIFY = FALSE)
)

populations <- data.frame(Isolate=rownames(otuMatrixNoLab_t),
                          stringsAsFactors = FALSE)
populations <- merge(populations, isolateInformation,
                     by.x="Isolate", by.y="Isolate", all.x=TRUE)
populations <- populations[,c("Isolate", "Country")]
populations <- populations[match(rownames(otuMatrixNoLab_t), populations$Isolate),]
populations$Isolate <- 1:nrow(populations)
```

A quick look at the outcome of the cross validation method.
```{r}
bestK(admix)
plot.df <- bestK(admix, plot = FALSE)
ggplot(plot.df, aes(x=K, y=CVerror)) + geom_point(size=7) +
  theme_bw() + xlab("K") + ylab("Cross Validation Error") +
  theme(text = element_text(size=17)) 
```

This indicates that with two hidden populations we produce the smallest cross validation error. This split is consistent with the split between the African and non-African isolates. The large seperation between Africa and non-Africa is consistent with what has been seen in non-VAR population structure analyses and is also usually observed in analyses of human population structure. Lets look at this split.

```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==2][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

It is also worth taking a look at the K from 1 to 10
```{r}
plotMultiK(admix[order(unlist(lapply(admix,getK)))], populations)
```

The small dip in the cross-validation error at K=6 appears to correspond with Admixture infering different hidden populations for the three African countries. At K=6 Iran is also distinct. For all K PNG does is not seperated from the African background cluster. This could be because of the different experimental method used in obtaining the PNG isolates.

We now take a closer look at the model with 6 underlying populations.
```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==6][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

Finally it is worth looking closer at a model with 10 underlying populations. That is the same number as the real number of countries present.

```{r}
t <- getQ(admix[unlist(lapply(admix,getK))==10][[1]])
rownames(t) <- 1:nrow(t)
plotBar(t, populations = populations)
```

A notable difference between K=6 and K=10 is that for K=6 Columbia appears to be very much within the African background cluster 2 whilst for K=10 cluster 7 indicates that Columbia is distinct from the vast majority of African isolates.

It should be noted that these mixtures are built off of the binary dataset which ignores any relationship between DBLa types that are only present once. Consequently, the JHMM model approach is more appropriate.

##RAxML
First we need to produce a binary fasta file
```{r, eval=FALSE}
text=ggplot2:::interleave(paste(">", rownames(otuMatrixNoLab_t), sep=""),
                          apply(otuMatrixNoLab_t, 1 , paste , collapse = "" ))
writeLines(text, con="./processed_data/DBLa_binary.fasta",
           sep="\n")
```

Now we can run RAxML

```{bash, eval=FALSE}
cd ./processed_data/
~/standard-RAxML-8.2.8/raxmlHPC-PTHREADS -m BINCAT -p 12345 -s DBLa_binary.fasta -n raxmlTree_T1 -T 20 | tee raxml.log
cd ..
```

We can now look at the output of RAxML.
```{r}
raxml <- read.tree("./processed_data/RAxML_result.raxmlTree_T1")

gtree <- ggtree(raxml, size=0.3, branch.length = "none", layout="circular")
gtree <- gtree %<+% isolateInformation
gtree + geom_tippoint(aes(colour=Country)) +
  colScale + theme(legend.position = "right")
```

##Alignment free comparison with FFP

First we need to split the sequences into seperate fasta files for each isolate
```{bash, eval=FALSE}
mkdir ffp_data
cd ffp_data
cp ../processed_data/combined_454_tessema.fas ./
cd ..
```

```{python, eval=FALSE}
from mungo.fasta import FastaReader
from collections import defaultdict

isolates = defaultdict(list)

for h,s in FastaReader("./processed_data/combined_454_tessema.fas"):
  isolates[h.split(".")[0]].append((h,s))

for iso in isolates:
  with open("./processed_data/"+iso+".fasta",'w') as outfile:
    for s in isolates[iso]:
      outfile.write(">"+s[0]+"\n"+s[1]+"\n")
```

We would now like to decide on an appropriate choice for the l-mer length. To investigate this we use the centroids after clustering the 3D7 isolate reads as a reference.
```{bash, eval=FALSE}
cd ffp_data
python ../scripts/clusterDBLa.py -o ./ -r 3D7.fasta

#Construct a word usage (vocabulary) profile
ffpvprof -e 40 -f 2 3D7_renamed_centroids.fasta > ../processed_data/ffp_word_usage.txt

#Construct a relative entropy profile
ffpreprof -e 40 3D7_renamed_centroids.fasta > ../processed_data/ffp_entropy_profile.txt

#We no longer need the lab isolates and can remove them
rm *3D7*.fasta
rm *DD2*.fasta
rm *HB3*.fasta

cd ..
```

We can now attempt to choose an appropriate value of l. First let look at word usage to get an idea of a lower bound.
```{r}
word_usage <- fread("./processed_data/ffp_word_usage.txt",
                    data.table = FALSE)
ggplot(word_usage, aes(x=V1, y=V2)) + geom_point() +
  theme_bw() + 
  xlab("k-mer feature length") +
  ylab("k-mer vocabulary size") +
  theme(text = element_text(size=15))
```

```{r}
entropy <- fread("./processed_data/ffp_entropy_profile.txt",
                    data.table = FALSE)
ggplot(entropy, aes(x=V1, y=V2)) + geom_point() +
  theme_bw() + 
  xlab("k-mer feature length") +
  ylab("cumlative relative entropy") +
  theme(text = element_text(size=15))
```

Thus a choice of l=20 appears to be appropriate.

We now want to get the set of sequences (excluding the labratory isolates) from which to cluster. We borrow those set up for the jumping HMM analysis (see supplementary_methods_2).

We can now run a script to calculate the ffp distance matrix. The original ffp script from xxx generated segment faults when we attempted to use it.
```{bash, eval=FALSE}
python ./scripts/ffp.py --kmer_length 20 --out ./processed_data/ffp_distance_matrix.phylip --seq ./processed_data/combined_454_tessema.fas --verbose
```

Finally a tree was built using fastme v2.1.4 with default parameters in interactive mode. We can now have a look at the resulting tree.

```{r}
ffp <- read.tree("./processed_data/ffp_distance_matrix.phylip_fastme_tree.txt")

isolateInformation$Country[isolateInformation$Country %in% c("3D7", "3D7xDD2", "DD2", "DD2xHB3", "HB3", "HB3xDD2")] <- "Lab"
isolateInformation <- isolateInformation[isolateInformation$Country!="Lab",]
groupInfo <- split(isolateInformation$Isolate, isolateInformation$Country)
ffp <- groupOTU(ffp, groupInfo)

gg <- ggtree(ffp, aes(color=group, label=node)
             , size=0.3, branch.length = "none", layout="circular")
gg <- gg + colScale +
  theme(legend.position="right")
gg
```

In a similar fashion to Yalcindag et al we remove the Peruvian and Venezulan isolates.
```{r, eval=FALSE}
distMatrix <- fread("./processed_data/ffp_distance_matrix.phylip", skip=1, header=FALSE, data.table = FALSE)

keep <- isolateInformation$Isolate[!(isolateInformation$Country %in% c("Peru", "Venezuela"))]
keep <- distMatrix$V1 %in% keep
distMatrix <- distMatrix[keep, c(TRUE, keep)]

cat((ncol(distMatrix)-1), '\n',  file = "./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip")
write.table(format(distMatrix, digits=10)
            , file="./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip"
            , sep=" ", row.names = FALSE
            , col.names = FALSE, quote = FALSE, append = TRUE)
```

Plot the tree without Peru and Venezuela
```{r}
# ffp <- read.tree("./processed_data/ffp_distance_matrix_noPeruVenezuela.phylip_fastme_tree.txt")
# 
# isolateInformationNoPeruVen <- isolateInformation[!(isolateInformation$Country %in% c("Peru", "Venezuela")),]
# 
# groupInfo <- isolateInformationNoPeruVen %>% group_by(Country) %>%
#   do(taxa_list = .$Isolate)
# 
# groups <- lapply(groupInfo$taxa_list, as.vector)
# names(groups) <- groupInfo$Country
# ffp <- groupOTU(ffp, groups)
# 
# gg <- ggtree(ffp, aes(color=group, label=node)
#              , size=0.3, branch.length = "none", layout="circular")
# gg <- gg + scale_color_manual(values=as.character(t_cols[names(t_cols) %in% names(groups)]),
#                               labels=names(groups)) +
#   theme(legend.position="right")
# gg
```

##Investigating association with severe disease segments

```{python, eval=FALSE}
from mungo.fasta import FastaReader
import sys,os

sig_dbla_clusters = {}

with open("./data/severe_disease_segments_plos_bio_2018.txt", 'rU') as infile:
	infile.next()
	for line in infile:
		line = line.strip().split("\t")
		if "DBLa" in line[0]:
			sig_dbla_clusters[line[0]] = line[8].split(",")


seq_dict = {}
for h,s in FastaReader("./data/combined_segments_from_plos_bio_2018.fasta"):
	seq_dict[h] = s


with open("./data/sig_dbla_segment_clusters.fasta", 'w') as outfile:
	for clust in sig_dbla_clusters:
		for seq in sig_dbla_clusters[clust]:
			outfile.write(">" + clust + "\n")
			outfile.write(seq_dict[seq] + "\n")
```

```{bash, eval=FALSE}
usearch -usearch_global ./data/sig_dbla_segment_clusters.fasta -db ./processed_data/combined_454_tessema_renamed_centroids_Protein.fasta -id 0.96 -blast6out ./processed_data/severe_var_plosbio2018_blast6out.txt -maxaccepts 0 -maxrejects 0
```

Appears only a small number of isolates from PNG include sequences from the severe data set. However these matched a region of the PNG sequences that is not present in the other data sets as the PNG data set was generated using Sanger sequencing. As we are only considering a small portion of the DBLa domain most of the other significant segments could not be searched for.

```{r}
severe.search.results <- fread("./processed_data/severe_var_plosbio2018_blast6out.txt", data.table = FALSE)
unique(severe.search.results$V1)
unique(gsub("\\..*", "", severe.search.results$V2))
```

We can also search for the homology blocks of Rask et al 2010.

```{bash, eval=FALSE}
hmmsearch --domtblout ./processed_data/rask_block_search_domtblout.txt --domT 9.7 --nonull2 --nobias ./data/rask_blocks.hmm ./processed_data/combined_454_tessema_renamed_centroids_Protein.fasta > ./processed_data/hmmsearch.out
```

```{r}
hmmsearch <- read.table("./processed_data/rask_block_search_domtblout.txt", sep = "" , header = FALSE,
                     na.strings ="", stringsAsFactors= FALSE, comment.char = "#")
hmmsearch <- hmmsearch[hmmsearch$V4 %in% c("Rask_block_219", "Rask_block_582", "Rask_block_47",
                                           "Rask_block_142", "Rask_block_126", "Rask_block_97",
                                           "Rask_block_121", "Rask_block_141", "Rask_block_150",
                                           "Rask_block_150", "Rask_block_183"),]
length(unique(hmmsearch$V1))
```

##Session Information
```{r}
sessionInfo()
```
